\section{Resultados}

\subsection{Análisis Univariante y Multivariante}

En \customref{fig:histogramas_variables} ya hemos visto los histogramas de las variables. Podemos complementar esto con los diagramas de cajas:

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{grafico_cajas}
    \caption{Gráficos de cajas de las variables de entrada}
\end{figure}

A la hora de borrar \textit{outliers}, de forma univariante, solo la variable \textit{Apariencia} los presenta. Concretamente, presenta 14 registros, lo que supone un 0.587\% del total de los registros, por que lo borramos dichos registros. Aplicando la misma transformación de datos, para no caer en \textit{data snooping}, borramos 2 filas en test, lo que supone un 0.335\%.

A la hora de borrar \textit{outliers}, de forma multivariante, borramos 13 filas del conjunto de entrenamiento, lo que supone un 0.084\%. Para no caer en \textit{data snooping}, no aplicamos este borrado usando la distancia \textit{Mahalanobis} sobre el conjunto de \textit{test}.

En \customref{fig:balanceo_clases} ya hemos visto el balanceo de las clases, con aproximadamente un 60\% de no empleables, 40\% de empleables.

El estudio de la normalidad univariante, apoyado en los gráficos \textit{qqplot} y el contraste de hipótesis nos muestra que \textbf{no tenemos normalidad univariante}, de forma muy contundente. Los gráficos \textit{qqplot} obtenidos son los siguientes:

\begin{figure}[H]
    \centering
    \begin{subfigure}{0.45\textwidth}
    \includegraphics[width=1.0\textwidth]{graficos_qqplot}
    \end{subfigure}
    \begin{subfigure}{0.45\textwidth}
        \includegraphics[width=1.0\textwidth]{graficos_qqplot_segunda}
    \end{subfigure}

    \caption{Gráficos \textit{qqplot} de las variables de entrada}
\end{figure}

La visualización de la matriz de correlaciones, junto con el \textit{test de esfericidad de Bartlett} nos dejan claro que las variables están correlacionadas. La matriz de correlaciones se muestra como la siguiente visualización:

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{matriz_correlaciones}
    \caption{Matriz de correlaciones}
\end{figure}

Podemos visualizar, en otro formato, los pares de variables que más correladas están entre sí:

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{rank_correlaciones}
    \caption{Pares de variables más correladas entre sí}
\end{figure}

Y también, podemos ver esto mismo en dos subconjuntos de datos, el de registros asociados a personas empleables y el de no empleables:

\begin{figure}[H]
    \centering
    \begin{subfigure}{0.45\textwidth}
        \includegraphics[width=1.0\textwidth]{rank_empleables}
        \caption{Candidatos empleables}
    \end{subfigure}
    \begin{subfigure}{0.45\textwidth}
        \includegraphics[width=1.0\textwidth]{rank_no_empleables}
        \caption{Candidatos no empleables}
    \end{subfigure}

    \caption{Pares de variables más correladas entre sí, según la empleabilidad}
\end{figure}

Los contrastes de hipótesis, que ya hemos comentado, nos indican que \textbf{NO tenemos normalidad multivariante}, como era de esperar al fallar la normalidad univariante.

Otro contraste de hipótesis nos indica que \textbf{NO tenemos homogeneidad de la varianza}. Aunque al fallar la normalidad multivariante, este resultado no es fiable. No es del todo relevante que el \textit{test} no sea fiable. Puesto que estamos comprobando los supuestos para los modelos discriminante, y la falta de normalidad ya hace que, independientemente de la homogeneidad de la varianza, no vayan a funcionar de forma óptima.

Por tanto, los dos \textbf{supuestos sobre los que se sustentan el discriminante lineal y cuadrático fallan}.


\subsection{Reducción de la dimensionalidad}

Esta parte es muy relevante en nuestro estudio. Porque producimos dos nuevos conjuntos de datos, que proporcionarán uno de los mejores resultados a la hora de clasificar, y porque además serán muy relevantes a la hora de estudiar la posible falta de meritocracia.

Además, mantenemos a partir de ahora tres conjuntos de datos:

\begin{enumerate}
    \item El conjunto de datos original, sobre el que realizamos el tratamiento ya mencionado
    \item El conjunto de datos original al que aplicamos \textit{PCA}
    \item El conjunto de datos original al que aplicamos \textit{FA}
\end{enumerate}

Esto porque a la hora de clasificar, tenemos que elegir todavía cuál es la mejor combinación de modelo-conjunto de datos. Y no todos los modelos necesariamente tengan los mejores resultados sobre el mismo conjunto de datos.

\subsubsection{Componentes Principales}

Veamos la varianza explicada, y la varianza explicada acumulada, por las componentes principales:

\begin{figure}[H]
    \centering
    \begin{subfigure}{0.45\textwidth}
        \includegraphics[width=1.0\textwidth]{pca_var_explicada}
        \caption{Proporción de la varianza explicada por las componentes principales}
    \end{subfigure}
    \begin{subfigure}{0.45\textwidth}
        \includegraphics[width=1.0\textwidth]{pca_var_explicada_acumulada}
        \caption{Proporción de la varianza explicada acumulada por las componentes principales}
    \end{subfigure}

    \caption{Información sobre la proporción de la varianza explicada por cada una de las componentes principales}
\end{figure}

Los resultados de los métodos para elegir el número de componentes principales son:

\begin{itemize}
    \item Regla de \textit{Abdi}: dos componentes
    \item Mínimo de Varianza explicada: cuatro componentes, buscando explicar al menos el 80\% de la varianza
    \item Método del codo: dos componentes
    \item Análisis paralelo: dos componentes
\end{itemize}

El método del codo y análisis paralelo se fundamentan en los siguientes gráficos:

\begin{figure}[H]
    \centering
    \begin{subfigure}{0.45\textwidth}
        \includegraphics[width=1.0\textwidth]{pca_codo}
        \caption{Gráfica del método del codo}
    \end{subfigure}
    \begin{subfigure}{0.45\textwidth}
        \includegraphics[width=1.0\textwidth]{pca_paralelo}
        \caption{Gráfica para el método paralelo}
    \end{subfigure}

    \caption{Gráficas sobre las que se fundamentan el método del codo y método del análisis paralelo}
\end{figure}

Por tanto, elegimos usar \textbf{dos componentes principales}

Tras realizar la transformación de los datos, podemos mostrar el siguiente gráfico:

\begin{figure}[H]
    \centering
    \includegraphics[width=0.60\textwidth]{scatter_plot_pca}
    \caption{Dos primeras componentes principales, coloreadas según la empleabilidad}
\end{figure}

Además, podemos visualizar la relevancia de las variables de entrada a la hora de generar las dos componentes principales:

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{pca_ejes}
    \caption{Importancia de las variables de entrada a la hora de calcular las dos primeras componentes principales}
\end{figure}

\subsubsection{Análisis Factorial}


Los resultados de los métodos para elegir el número de variables latentes son:

\begin{itemize}
    \item Método del codo: un factor latente
    \item Análisis paralelo: dos factores latentes
\end{itemize}

Esto se fundamenta en los siguientes gráficos:

\begin{figure}[H]
    \centering
    \begin{subfigure}{0.45\textwidth}
        \includegraphics[width=1.0\textwidth]{fa_codo}
        \caption{Gráfica del método del codo}
    \end{subfigure}
    \begin{subfigure}{0.45\textwidth}
        \includegraphics[width=1.0\textwidth]{fa_paralelo}
        \caption{Gráfica para el método paralelo}
    \end{subfigure}

    \caption{Gráficas sobre las que se fundamentan el método del codo y método del análisis paralelo}
\end{figure}

Con un contraste de hipótesis, vemos que es suficiente con un factor latente, y por tanto, también con dos factores latentes. Podemos visualizar cómo se construyen las variables latentes, tanto en el caso de una o dos variables latentes:

\begin{figure}[H]
    \centering
    \begin{subfigure}{0.45\textwidth}
        \includegraphics[width=1.0\textwidth]{var_latentes_uno}
        \caption{Combinación de las variables de entrada, para un solo factor latente}
    \end{subfigure}
    \begin{subfigure}{0.45\textwidth}
        \includegraphics[width=1.0\textwidth]{var_latentes_dos}
        \caption{Combinación de las variables de entrada, para dos factores latentes}
    \end{subfigure}

    \caption{Gráfica que muestra cómo se combinan las variables para calcular los factores latentes, para un solo factor latente y para dos factores latentes}
\end{figure}

Por los motivos que comentamos en \customref{section:Discusion}, al final decidimos quedarnos con dos variables latentes, aunque sea suficiente con una variable latente.

\subsection{Exploración de hiperparámetros}

\textit{XGBOOST} tiene hiperparámetros que podemos optimizar usando \textit{k-Fold Cross Validation}. Sin embargo, por la potencia del modelo, basta con que usemos unos parámetros que consideramos razonables, y los modificamos ligeramente para obtener el resultado final. Usamos los siguientes hiperparámetros en este modelo:

\begin{itemize}
    \item \lstinline{max_depth} = 10
    \item \lstinline{eta} = 0.3
    \item \lstinline{nrounds} = 100
\end{itemize}

Los resultados se resumen en la siguiente tabla:

\begin{table}[H]
\centering
\begin{tabular}{|l|l|l|}
    \hline
    Modelo                   & Dataset      & Accuracy      \\
    \hline
    Discriminante Lineal     & Original     & 0.5915605     \\
    Discriminante Lineal     & PCA          & 0.5334985     \\
    Discriminante Lineal     & FA           & 0.5284333     \\
    Discriminante Cuadrático & Original     & 0.6891568     \\
    Discriminante Cuadrático & PCA          & 0.5615132     \\
    Discriminante Cuadrático & FA           & 0.587775      \\
    XGBOOST                  & Original     & 0.9014924     \\
    \textbf{XGBOOST}         & \textbf{PCA} & \textbf{0.9046639} \\
    XGBOOST                  & FA           & 0.9036134     \\
    \hline

\end{tabular}
\caption{Resultados de \textit{k-Fold Cross Validation}}
\label{table:cross_validation}
\end{table}

Vemos que los mejores resultados se obtienen con \textit{XGBOOST} sobre el conjunto de \textit{PCA}. El discriminante cuadrático y el discriminante lineal obtienen sus mejores resultados sobre el conjunto de datos original.

\subsection{Clasificación}

Aunque \textbf{ya hemos decidido que el mejor modelo es \textit{XGBOOST}} sobre los datos a los que aplicamos \textit{PCA}, entrenamos y validamos los tres modelos, cada uno con el conjunto de datos sobre el que obtiene mejores resultados. Con esto, \textbf{podemos realizar un estudio sobre el comportamiento de los tres modelos}.

Los coeficientes (en valor absoluto) del discriminante lineal, que discutiremos en \customref{section:Discusion}, se visualizan en la siguiente figura:

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{coeficientes_lda}
    \caption{Visualización de los valores absolutos de los coeficientes del modelo discriminante lineal}
\end{figure}

El paquete de \textit{XGBOOST} nos otorga una función para mostrar la importancia de cada variable. Mostramos dicha importancia, tanto para el modelo sobre \textit{PCA} (que es el que escogemos por lo visto en \customref{table:cross_validation}) como para el modelo sobre el conjunto de datos original (que solo usamos para visualizar dicha relevancia):

\begin{figure}[H]
    \centering
    \begin{subfigure}{0.45\textwidth}
        \includegraphics[width=1.0\textwidth]{xgb_coeff_pca}
        \caption{Modelo sobre el conjunto de datos al que aplicamos \textit{PCA}}
    \end{subfigure}
    \begin{subfigure}{0.45\textwidth}
        \includegraphics[width=1.0\textwidth]{xgb_coeff_orig}
        \caption{Modelo sobre el conjunto de datos original}
    \end{subfigure}

    \caption{Importancia de las variables a la hora de construir el modelo \textit{XGBOOST}}
\end{figure}

\subsection{Validación}

Empezamos mostrando el \textit{accuracy} de los modelos, tanto en entrenamiento como en \textit{test} \footnotemark:

\footnotetext{De esta forma, podemos diagnosticar ciertos problemas, principalmente, el \textit{overfitting}}

\begin{table}[H]
\centering
\begin{tabular}{|l|l|l|l}
\hline
    Modelo               & \textit{Train acc} & \textit{Test acc}          \\
\hline
Discriminante lineal     & 0.591178965224767  & 0.598319327731092 \\
Discriminante cuadrático & 0.706106870229008  & 0.697478991596639 \\
\textit{XGBOOST}         & 0.913910093299406  & 0.890756302521008 \\
\hline
\end{tabular}
\caption{\textit{Accuracy} de los tres modelos entrenados}
\end{table}

\subsection{Experimento adicional}

Como hemos visto que el mejor modelo es \textit{XGBOOST}, y como nos da algunas facilidades para interpretar los modelos obtenidos, usaremos este modelo. Además, usaremos el conjunto de datos original para simplificar el desarrollo del experimento. Esto porque, para aplicar \textit{PCA} o \textit{FA}, habría que aplicarlo a los dos conjuntos por separado, y ver si se obtienen mejores resultados que sin aplicar la transformación, usando \textit{k-fold Cross Validation}.

Realizamos la separación del conjunto de datos original en dos, uno conteniendo las variables que consideramos meritocráticas, y otro con las variables que consideramos no meritocráticas.

Como variables meritocráticas consideramos:

\begin{itemize}
    \item Rendimiento académico
    \item Agilidad mental
    \item Habilidad para presentar ideas
    \item Habilidades de comunicación
\end{itemize}

Como variables no meritocráticas consideramos:
\begin{itemize}
    \item Condición físicas
    \item Apariencia
    \item Formas de hablar
    \item Confianza
\end{itemize}

Realizamos un ajuste de hiperparámetros de los dos modelos \textit{XGBOOST}. Esto lo realizamos usando \textit{k-Fold Cross Validation} con \textit{Grid Search}. Los mejores parámetros para cada modelo son:

\begin{itemize}
    \item Modelo meritocrático: \lstinline{nrounds} = 480, \lstinline{max_depth} = 3, \lstinline{eta} = 0.3
    \item Modelo no meritocrático: \lstinline{nrounds} = 120, \lstinline{max_depth} = 5, \lstinline{eta} = 0.1
    \item Para el resto de parámetros, usamos el valor por defecto
\end{itemize}

Tras entrenar los modelos, los resultados obtenidos son:

\begin{table}[H]
\centering
\begin{tabular}{|l|l|l|l}
\hline
Conjunto de datos    & Train Acc         & Test Acc              \\
\hline
Meritocrático        & 0.733248515691264 & 0.694117647058824     \\
    \textbf{No meritocrático} & 0.719677692960136 & \textbf{0.715966386554622} \\
\hline

\end{tabular}
\caption{Resultados del experimento}
\end{table}

% TODO -- poner aqui las matrices de confusion

